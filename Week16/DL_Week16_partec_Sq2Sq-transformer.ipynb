{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOb1gdAhapOIfjk3FUUHfk8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["\n","Tutoriales\n","https://www.tensorflow.org/text\n","\n","https://www.tensorflow.org/text/tutorials/nmt_with_attention\n","\n","Datasets\n","https://www.manythings.org/anki/"],"metadata":{"id":"CsXt72V4eq37"}},{"cell_type":"markdown","source":["# Librerías y componentes"],"metadata":{"id":"hOe7-3V4zeMc"}},{"cell_type":"code","source":["import tensorflow as tf\n","import string\n","import re\n","import random\n","import zipfile\n","\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import TextVectorization,GlobalMaxPooling1D, Dropout, MultiHeadAttention, Dense, LayerNormalization, Embedding, GRU, Bidirectional\n"],"metadata":{"id":"y1fwnxRC03iB","executionInfo":{"status":"ok","timestamp":1762787579120,"user_tz":300,"elapsed":17901,"user":{"displayName":"Diego Renza Torres","userId":"02863859277986193516"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["# Dataset (archivo)"],"metadata":{"id":"MP37EYOHllcc"}},{"cell_type":"code","source":["!wget http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uGPEOGuTurF9","executionInfo":{"status":"ok","timestamp":1762787600744,"user_tz":300,"elapsed":1533,"user":{"displayName":"Diego Renza Torres","userId":"02863859277986193516"}},"outputId":"aadfb751-e1bb-46d9-e360-47c7be767fd6"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["--2025-11-10 15:13:19--  http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n","Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.130.207, 74.125.68.207, 74.125.24.207, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.130.207|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2638744 (2.5M) [application/zip]\n","Saving to: ‘spa-eng.zip’\n","\n","spa-eng.zip         100%[===================>]   2.52M  2.11MB/s    in 1.2s    \n","\n","2025-11-10 15:13:20 (2.11 MB/s) - ‘spa-eng.zip’ saved [2638744/2638744]\n","\n"]}]},{"cell_type":"code","source":["with zipfile.ZipFile('/content/spa-eng.zip', 'r') as zip_ref:\n","    zip_ref.extractall('/content/')"],"metadata":{"id":"0K6zEcHYPgny","executionInfo":{"status":"ok","timestamp":1762787603847,"user_tz":300,"elapsed":56,"user":{"displayName":"Diego Renza Torres","userId":"02863859277986193516"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# Dataset (preparación)"],"metadata":{"id":"YoEMJ84D0zSW"}},{"cell_type":"code","source":["archivo = \"spa-eng/spa.txt\"\n","with open(archivo) as f:\n","  ejemplos = f.read().split(\"\\n\")[:-1]\n","dataset = []"],"metadata":{"id":"0BZogyp1vKyp","executionInfo":{"status":"ok","timestamp":1762787605764,"user_tz":300,"elapsed":123,"user":{"displayName":"Diego Renza Torres","userId":"02863859277986193516"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["for line in ejemplos:\n","  salida, entrada = line.split(\"\\t\")  # par hacerlo español a inglés\n","\n","  # Cambios DRT\n","  salida = \"[start] \" + salida + \" [end]\"\n","  dataset.append((entrada, salida))\n","\n","print(random.choice(dataset))"],"metadata":{"id":"_rMdGaZZvaTx","executionInfo":{"status":"ok","timestamp":1762787608462,"user_tz":300,"elapsed":91,"user":{"displayName":"Diego Renza Torres","userId":"02863859277986193516"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"dffc989d-8c24-431c-bf48-2ca51038d10e"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["('El precio no tiene importancia.', \"[start] The price isn't important. [end]\")\n"]}]},{"cell_type":"code","source":["# Aleatorizar\n","random.shuffle(dataset)\n","no_muestras_val = int(0.15 * len(dataset))\n","no_muestras_train = len(dataset) - 2 * no_muestras_val\n","train_pairs = dataset[:no_muestras_train]\n","val_pairs = dataset[no_muestras_train:no_muestras_train + no_muestras_val]\n","test_pairs = dataset[no_muestras_train + no_muestras_val:]"],"metadata":{"id":"d9dSPdSnv50z","executionInfo":{"status":"ok","timestamp":1762787610000,"user_tz":300,"elapsed":39,"user":{"displayName":"Diego Renza Torres","userId":"02863859277986193516"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["caracteres_a_eliminar = string.punctuation + \"¿\"\n","caracteres_a_eliminar = caracteres_a_eliminar.replace(\"[\", \"\")\n","caracteres_a_eliminar = caracteres_a_eliminar.replace(\"]\", \"\")\n","\n","def estandarizacion(input_string):\n","  lowercase = tf.strings.lower(input_string)\n","  return tf.strings.regex_replace(\n","      lowercase, f\"[{re.escape(caracteres_a_eliminar)}]\", \"\")\n","\n","vocab_size = 15000\n","sequence_length = 20\n","\n","# Hasta aquí OK\n","\n","vectorizacion_entrada = TextVectorization(\n","    max_tokens=vocab_size,\n","    output_mode=\"int\",\n","    output_sequence_length=sequence_length,\n",")\n","\n","vectorizacion_salida = TextVectorization(\n","    max_tokens=vocab_size,\n","    output_mode=\"int\",\n","    output_sequence_length=sequence_length + 1,\n","    standardize=estandarizacion,\n",")\n","\n","train_entrada_texts = [pair[0] for pair in train_pairs]\n","train_salida_texts = [pair[1] for pair in train_pairs]\n","vectorizacion_entrada.adapt(train_entrada_texts)\n","vectorizacion_salida.adapt(train_salida_texts)"],"metadata":{"id":"TH--LnVswUlw","executionInfo":{"status":"ok","timestamp":1762787613470,"user_tz":300,"elapsed":1752,"user":{"displayName":"Diego Renza Torres","userId":"02863859277986193516"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["batch_size = 64\n","\n","def format_dataset(ent, sal):\n","  ent = vectorizacion_entrada(ent)\n","  sal = vectorizacion_salida(sal)\n","  return ({\n","      \"entrada\": ent,\n","      \"salida\": sal[:, :-1],\n","      }, sal[:, 1:])\n","\n","def make_dataset(pairs):\n","  ent_texts, sal_texts = zip(*pairs)\n","  ent_texts = list(ent_texts)\n","  sal_texts = list(sal_texts)\n","  dataset = tf.data.Dataset.from_tensor_slices((ent_texts, sal_texts))\n","  dataset = dataset.batch(batch_size)\n","  dataset = dataset.map(format_dataset, num_parallel_calls=4)\n","  return dataset.shuffle(2048).prefetch(16).cache()\n","\n","train_ds = make_dataset(train_pairs)\n","val_ds = make_dataset(val_pairs)"],"metadata":{"id":"ednLsuX1w_QQ","executionInfo":{"status":"ok","timestamp":1762787617121,"user_tz":300,"elapsed":618,"user":{"displayName":"Diego Renza Torres","userId":"02863859277986193516"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Dataset output\n","for inputs, targets in train_ds.take(1):\n","  print(f\"inputs['entrada'].shape: {inputs['entrada'].shape}\")\n","  print(f\"inputs['salida'].shape: {inputs['salida'].shape}\")\n","  print(f\"targets.shape: {targets.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LgLMYiOaxOmC","executionInfo":{"status":"ok","timestamp":1762787619690,"user_tz":300,"elapsed":558,"user":{"displayName":"Diego Renza Torres","userId":"02863859277986193516"}},"outputId":"fa9bb2e2-f217-4387-843a-55561fdc86b2"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["inputs['entrada'].shape: (64, 20)\n","inputs['salida'].shape: (64, 20)\n","targets.shape: (64, 20)\n"]}]},{"cell_type":"markdown","source":["#Transformer encoder"],"metadata":{"id":"1Yy0FXMHSx4t"}},{"cell_type":"code","source":["class TransformerEncoder(layers.Layer):\n","    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n","        super().__init__(**kwargs)\n","        self.embed_dim = embed_dim\n","        self.dense_dim = dense_dim\n","        self.num_heads = num_heads\n","        self.attention = MultiHeadAttention(\n","            num_heads=num_heads, key_dim=embed_dim)\n","        self.dense_proj = keras.Sequential(\n","            [Dense(dense_dim, activation=\"relu\"),\n","             Dense(embed_dim),]\n","        )\n","        self.layernorm_1 = LayerNormalization()\n","        self.layernorm_2 = LayerNormalization()\n","\n","    def call(self, inputs, mask=None):\n","        if mask is not None:\n","            mask = mask[:, tf.newaxis, :]\n","        attention_output = self.attention(\n","            inputs, inputs, attention_mask=mask)\n","        proj_input = self.layernorm_1(inputs + attention_output)\n","        proj_output = self.dense_proj(proj_input)\n","        return self.layernorm_2(proj_input + proj_output)\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update({\n","            \"embed_dim\": self.embed_dim,\n","            \"num_heads\": self.num_heads,\n","            \"dense_dim\": self.dense_dim,\n","        })\n","        return config"],"metadata":{"id":"xs7uEcdcSzCX","executionInfo":{"status":"ok","timestamp":1762787623531,"user_tz":300,"elapsed":34,"user":{"displayName":"Diego Renza Torres","userId":"02863859277986193516"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["# Transformer-based model"],"metadata":{"id":"cUqV8JKSxrrE"}},{"cell_type":"code","source":["class TransformerDecoder(layers.Layer):\n","    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n","        super().__init__(**kwargs)\n","        self.embed_dim = embed_dim\n","        self.dense_dim = dense_dim\n","        self.num_heads = num_heads\n","        self.attention_1 = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=embed_dim)\n","        self.attention_2 = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=embed_dim)\n","        self.dense_proj = keras.Sequential(\n","            [layers.Dense(dense_dim, activation=\"relu\"),\n","             layers.Dense(embed_dim),]\n","        )\n","        self.layernorm_1 = layers.LayerNormalization()\n","        self.layernorm_2 = layers.LayerNormalization()\n","        self.layernorm_3 = layers.LayerNormalization()\n","        self.supports_masking = True\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update({\n","            \"embed_dim\": self.embed_dim,\n","            \"num_heads\": self.num_heads,\n","            \"dense_dim\": self.dense_dim,\n","        })\n","        return config\n","\n","    def get_causal_attention_mask(self, inputs):\n","        input_shape = tf.shape(inputs)\n","        batch_size, sequence_length = input_shape[0], input_shape[1]\n","        i = tf.range(sequence_length)[:, tf.newaxis]\n","        j = tf.range(sequence_length)\n","        mask = tf.cast(i >= j, dtype=\"int32\")\n","        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n","        mult = tf.concat(\n","            [tf.expand_dims(batch_size, -1),\n","             tf.constant([1, 1], dtype=tf.int32)], axis=0)\n","        return tf.tile(mask, mult)\n","\n","    def call(self, inputs, encoder_outputs, mask=None):\n","        causal_mask = self.get_causal_attention_mask(inputs)\n","        if mask is not None:\n","            padding_mask = tf.cast(\n","                mask[:, tf.newaxis, :], dtype=\"int32\")\n","            padding_mask = tf.minimum(padding_mask, causal_mask)\n","        else:\n","            padding_mask = mask\n","        attention_output_1 = self.attention_1(\n","            query=inputs,\n","            value=inputs,\n","            key=inputs,\n","            attention_mask=causal_mask)\n","        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n","        attention_output_2 = self.attention_2(\n","            query=attention_output_1,\n","            value=encoder_outputs,\n","            key=encoder_outputs,\n","            attention_mask=padding_mask,\n","        )\n","        attention_output_2 = self.layernorm_2(\n","            attention_output_1 + attention_output_2)\n","        proj_output = self.dense_proj(attention_output_2)\n","        return self.layernorm_3(attention_output_2 + proj_output)"],"metadata":{"id":"DpnVv0x8RrtV","executionInfo":{"status":"ok","timestamp":1762787627295,"user_tz":300,"elapsed":6,"user":{"displayName":"Diego Renza Torres","userId":"02863859277986193516"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["#Positional embedding"],"metadata":{"id":"6K779igpS4IU"}},{"cell_type":"code","source":["class PositionalEmbedding(layers.Layer):\n","    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n","        super().__init__(**kwargs)\n","        self.token_embeddings = layers.Embedding(\n","            input_dim=input_dim, output_dim=output_dim)\n","        self.position_embeddings = layers.Embedding(\n","            input_dim=sequence_length, output_dim=output_dim)\n","        self.sequence_length = sequence_length\n","        self.input_dim = input_dim\n","        self.output_dim = output_dim\n","\n","    def call(self, inputs):\n","        length = tf.shape(inputs)[-1]\n","        positions = tf.range(start=0, limit=length, delta=1)\n","        embedded_tokens = self.token_embeddings(inputs)\n","        embedded_positions = self.position_embeddings(positions)\n","        return embedded_tokens + embedded_positions\n","\n","    def compute_mask(self, inputs, mask=None):\n","        # Wrap tf.math.not_equal in a Lambda layer\n","        return layers.Lambda(lambda x: tf.math.not_equal(x, 0))(inputs)\n","\n","    def get_config(self):\n","        config = super(PositionalEmbedding, self).get_config()\n","        config.update({\n","            \"output_dim\": self.output_dim,\n","            \"sequence_length\": self.sequence_length,\n","            \"input_dim\": self.input_dim,\n","        })\n","        return config"],"metadata":{"id":"GClon4HjW-uj","executionInfo":{"status":"ok","timestamp":1762787630063,"user_tz":300,"elapsed":19,"user":{"displayName":"Diego Renza Torres","userId":"02863859277986193516"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["# Modelo"],"metadata":{"id":"xHJbZ1WU0irp"}},{"cell_type":"code","source":["embed_dim = 256\n","dense_dim = 2048\n","num_heads = 8\n","\n","encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"entrada\")\n","x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n","encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n","\n","decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"salida\")\n","x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n","x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n","x = layers.Dropout(0.5)(x)\n","decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n","transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"],"metadata":{"id":"xwKB3Cqhxtlf","executionInfo":{"status":"ok","timestamp":1762787637315,"user_tz":300,"elapsed":4693,"user":{"displayName":"Diego Renza Torres","userId":"02863859277986193516"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1934d91c-30db-490c-b11e-3b60d6fa2db2"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:965: UserWarning: Layer 'transformer_encoder' (of type TransformerEncoder) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","source":["# Entrenamiento"],"metadata":{"id":"sJzUpxaw0o_2"}},{"cell_type":"code","source":["transformer.compile(\n","    optimizer=\"rmsprop\",\n","    loss=\"sparse_categorical_crossentropy\",\n","    metrics=[\"accuracy\"])\n","\n","transformer.fit(train_ds, epochs=10, validation_data=val_ds)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NdmrRjOqyOh5","outputId":"01891f4e-b780-401e-d23f-cfeadceae4ff","executionInfo":{"status":"ok","timestamp":1762788583438,"user_tz":300,"elapsed":943133,"user":{"displayName":"Diego Renza Torres","userId":"02863859277986193516"}}},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 78ms/step - accuracy: 0.1466 - loss: 4.5376 - val_accuracy: 0.2487 - val_loss: 2.5452\n","Epoch 2/10\n","\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 70ms/step - accuracy: 0.2543 - loss: 2.4769 - val_accuracy: 0.2838 - val_loss: 1.9760\n","Epoch 3/10\n","\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 71ms/step - accuracy: 0.2841 - loss: 1.9568 - val_accuracy: 0.2936 - val_loss: 1.8094\n","Epoch 4/10\n","\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 71ms/step - accuracy: 0.2985 - loss: 1.7119 - val_accuracy: 0.2997 - val_loss: 1.7352\n","Epoch 5/10\n","\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 71ms/step - accuracy: 0.3078 - loss: 1.5597 - val_accuracy: 0.3040 - val_loss: 1.6968\n","Epoch 6/10\n","\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 71ms/step - accuracy: 0.3144 - loss: 1.4558 - val_accuracy: 0.3054 - val_loss: 1.6971\n","Epoch 7/10\n","\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 71ms/step - accuracy: 0.3198 - loss: 1.3806 - val_accuracy: 0.3069 - val_loss: 1.6949\n","Epoch 8/10\n","\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 70ms/step - accuracy: 0.3240 - loss: 1.3207 - val_accuracy: 0.3070 - val_loss: 1.7193\n","Epoch 9/10\n","\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 70ms/step - accuracy: 0.3274 - loss: 1.2769 - val_accuracy: 0.3070 - val_loss: 1.7397\n","Epoch 10/10\n","\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 70ms/step - accuracy: 0.3305 - loss: 1.2337 - val_accuracy: 0.3056 - val_loss: 1.7643\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7df394ba4c50>"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["# Evaluación"],"metadata":{"id":"hQmYTfrQ0r8u"}},{"cell_type":"code","source":["# Translate\n","\n","import numpy as np\n","sal_vocab = vectorizacion_salida.get_vocabulary()\n","sal_index_lookup = dict(zip(range(len(sal_vocab)), sal_vocab))\n","max_decoded_sentence_length = 20\n","\n","def decode_sequence(input_sentence):\n","    tokenized_input_sentence = vectorizacion_entrada([input_sentence])\n","    decoded_sentence = \"[start]\"\n","    for i in range(max_decoded_sentence_length):\n","        tokenized_target_sentence = vectorizacion_salida(\n","            [decoded_sentence])[:, :-1]\n","        predictions = transformer(\n","            [tokenized_input_sentence, tokenized_target_sentence])\n","        sampled_token_index = np.argmax(predictions[0, i, :])\n","        sampled_token = sal_index_lookup[sampled_token_index]\n","        decoded_sentence += \" \" + sampled_token\n","        if sampled_token == \"[end]\":\n","            break\n","    return decoded_sentence"],"metadata":{"id":"tU8SG55IyVNP","executionInfo":{"status":"ok","timestamp":1762788883633,"user_tz":300,"elapsed":35,"user":{"displayName":"Diego Renza Torres","userId":"02863859277986193516"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["test_ent_texts = [pair[0] for pair in test_pairs]\n","for _ in range(3):\n","    frase_entrada = random.choice(test_ent_texts)\n","    print(\"-\")\n","    print(frase_entrada)\n","    print(decode_sequence(frase_entrada))"],"metadata":{"id":"OqmCNA8B6KD-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762788892197,"user_tz":300,"elapsed":6395,"user":{"displayName":"Diego Renza Torres","userId":"02863859277986193516"}},"outputId":"5130f763-3782-4db8-a5eb-070c40c17f0f"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["-\n","Olvidé su nombre.\n","[start] i forgot his name [end]\n","-\n","Yo ni siquiera estuve en Boston la noche que mataron a Tom.\n","[start] i wasnt even in boston tom than tom was killed [end]\n","-\n","No iré mañana a la escuela.\n","[start] i wont go to school tomorrow [end]\n"]}]},{"cell_type":"code","source":["frase_entrada = input('Ingrese frase en español: ')\n","\n","print(frase_entrada)\n","print(decode_sequence(frase_entrada))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zm4kNjfO3QfH","executionInfo":{"status":"ok","timestamp":1762788917723,"user_tz":300,"elapsed":20193,"user":{"displayName":"Diego Renza Torres","userId":"02863859277986193516"}},"outputId":"457f1cb2-bce6-4e35-ea5b-236e51a7385d"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Ingrese frase en español: El próximo año será mi sabático\n","El próximo año será mi sabático\n","[start] the next year will be my mind [end]\n"]}]}]}