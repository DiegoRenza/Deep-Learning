{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPjI4H8Vx2paD5rGtl1FPO9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Dataset\n","\n","https://www.kaggle.com/datasets/jensenbaxter/10dataset-text-document-classification"],"metadata":{"id":"MP37EYOHllcc"}},{"cell_type":"code","source":["import zipfile\n","with zipfile.ZipFile('/content/Dataset_text.zip', 'r') as zip_ref:\n","    zip_ref.extractall('/content/Dataset_text/')"],"metadata":{"id":"0K6zEcHYPgny","executionInfo":{"status":"ok","timestamp":1731424974739,"user_tz":300,"elapsed":888,"user":{"displayName":"Diego Renza Torres","userId":"02863859277986193516"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["Lectura por lotes desde archivo"],"metadata":{"id":"lfMHHpPzl7ur"}},{"cell_type":"code","source":["from tensorflow import keras\n","batch_size = 32\n","\n","train_ds = keras.utils.text_dataset_from_directory(\n","    \"/content/Dataset_text\",\n","    batch_size=batch_size,\n","    validation_split=0.2,\n","    label_mode=\"categorical\",\n","    seed = 2023,\n","    subset=\"training\",\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zIfK7L4DPstR","executionInfo":{"status":"ok","timestamp":1731424991093,"user_tz":300,"elapsed":16120,"user":{"displayName":"Diego Renza Torres","userId":"02863859277986193516"}},"outputId":"0f2408ba-b90b-40db-c442-21f53eaaa3a4"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1000 files belonging to 10 classes.\n","Using 800 files for training.\n"]}]},{"cell_type":"code","source":["val_ds = keras.utils.text_dataset_from_directory(\n","    \"/content/Dataset_text\",\n","    batch_size=batch_size,\n","    validation_split=0.2,\n","    label_mode=\"categorical\",\n","    seed = 2023,\n","    subset=\"validation\",\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"76Z6RXFqPu_i","executionInfo":{"status":"ok","timestamp":1731424991094,"user_tz":300,"elapsed":4,"user":{"displayName":"Diego Renza Torres","userId":"02863859277986193516"}},"outputId":"d1b2331c-bbee-427c-a7b9-3b5bd749ee6a"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1000 files belonging to 10 classes.\n","Using 200 files for validation.\n"]}]},{"cell_type":"markdown","source":["Vectorización de datos"],"metadata":{"id":"bOLr4Akul-YI"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import TextVectorization,GlobalMaxPooling1D, Dropout, MultiHeadAttention, Dense, LayerNormalization, Embedding\n","\n","max_length = 600\n","max_tokens = 20000\n","text_vectorization = TextVectorization(\n","    max_tokens=max_tokens,\n","    output_mode=\"int\",\n","    output_sequence_length=max_length,    # Limitar la entrada a 600 palabras\n",")\n","\n","# Extraer solo el texto (features) de los datos de entrada para calcular el vocabulario\n","text_only_train_ds = train_ds.map(lambda x, y: x)\n","\n","text_vectorization.adapt(text_only_train_ds)\n","\n","int_train_ds = train_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)\n","\n","int_val_ds = val_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)"],"metadata":{"id":"VOBbKe1dPyY6","executionInfo":{"status":"ok","timestamp":1731424992018,"user_tz":300,"elapsed":926,"user":{"displayName":"Diego Renza Torres","userId":"02863859277986193516"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["# Transformer encoder"],"metadata":{"id":"V3XYnb41mD8o"}},{"cell_type":"code","execution_count":5,"metadata":{"id":"ednGtJkTM0qj","executionInfo":{"status":"ok","timestamp":1731424992018,"user_tz":300,"elapsed":3,"user":{"displayName":"Diego Renza Torres","userId":"02863859277986193516"}}},"outputs":[],"source":["class TransformerEncoder(layers.Layer):\n","    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n","        super().__init__(**kwargs)\n","        self.embed_dim = embed_dim\n","        self.dense_dim = dense_dim\n","        self.num_heads = num_heads\n","        self.attention = MultiHeadAttention(\n","            num_heads=num_heads, key_dim=embed_dim)\n","        self.dense_proj = keras.Sequential(\n","            [Dense(dense_dim, activation=\"relu\"),\n","             Dense(embed_dim),]\n","        )\n","        self.layernorm_1 = LayerNormalization()\n","        self.layernorm_2 = LayerNormalization()\n","\n","    def call(self, inputs, mask=None):\n","        if mask is not None:\n","            mask = mask[:, tf.newaxis, :]\n","        attention_output = self.attention(\n","            inputs, inputs, attention_mask=mask)\n","        proj_input = self.layernorm_1(inputs + attention_output)\n","        proj_output = self.dense_proj(proj_input)\n","        return self.layernorm_2(proj_input + proj_output)\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update({\n","            \"embed_dim\": self.embed_dim,\n","            \"num_heads\": self.num_heads,\n","            \"dense_dim\": self.dense_dim,\n","        })\n","        return config"]},{"cell_type":"markdown","source":["# Positional embedding"],"metadata":{"id":"sl4vXBW1r0_J"}},{"cell_type":"code","source":["class PositionalEmbedding(layers.Layer):\n","    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n","        super().__init__(**kwargs)\n","        self.token_embeddings = Embedding(                  # Capa embedding para los tokens\n","            input_dim=input_dim, output_dim=output_dim)\n","        self.position_embeddings = Embedding(                   # Capa embedding para la posición. Requiere conocer previamente la longitud de la secuencia\n","            input_dim=sequence_length, output_dim=output_dim)\n","        self.sequence_length = sequence_length\n","        self.input_dim = input_dim\n","        self.output_dim = output_dim\n","\n","    def call(self, inputs):\n","        length = tf.shape(inputs)[-1]\n","        positions = tf.range(start=0, limit=length, delta=1)\n","        embedded_tokens = self.token_embeddings(inputs)\n","        embedded_positions = self.position_embeddings(positions)\n","        return embedded_tokens + embedded_positions\n","\n","    def compute_mask(self, inputs, mask=None):\n","        # Wrap tf.math.not_equal in a Lambda layer\n","        return layers.Lambda(lambda x: tf.math.not_equal(x, 0))(inputs)\n","\n","    def get_config(self):                             # Serialización\n","        config = super().get_config()\n","        config.update({\n","            \"output_dim\": self.output_dim,\n","            \"sequence_length\": self.sequence_length,\n","            \"input_dim\": self.input_dim,\n","        })\n","        return config"],"metadata":{"id":"9dLDRYCUr5cy","executionInfo":{"status":"ok","timestamp":1731425031939,"user_tz":300,"elapsed":227,"user":{"displayName":"Diego Renza Torres","userId":"02863859277986193516"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["# Modelo (Self attention)"],"metadata":{"id":"1H24s6LXmKMF"}},{"cell_type":"code","source":["vocab_size = 20000\n","sequence_length = 600\n","embed_dim = 256\n","num_heads = 2\n","dense_dim = 32\n","\n","inputs = tf.keras.Input(shape=(None,), dtype=\"int64\")\n","\n","x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(inputs)\n","x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n","x = GlobalMaxPooling1D()(x)\n","x = Dropout(0.5)(x)\n","outputs = Dense(10, activation=\"softmax\")(x)\n","\n","model = keras.Model(inputs, outputs)\n","\n","model.compile(optimizer=\"rmsprop\",\n","              loss=\"categorical_crossentropy\",\n","              metrics=[\"accuracy\"])\n","\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"id":"zpkJ_3-FNxXN","executionInfo":{"status":"ok","timestamp":1731425033957,"user_tz":300,"elapsed":471,"user":{"displayName":"Diego Renza Torres","userId":"02863859277986193516"}},"outputId":"efe17c23-0fb6-4bdb-aa45-c958eba47c10"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'transformer_encoder' (of type TransformerEncoder) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"functional_1\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ positional_embedding_1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │      \u001b[38;5;34m5,273,600\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n","│ (\u001b[38;5;33mPositionalEmbedding\u001b[0m)     │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ lambda (\u001b[38;5;33mLambda\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ transformer_encoder       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │        \u001b[38;5;34m543,776\u001b[0m │ positional_embedding_… │\n","│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)      │                        │                │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ global_max_pooling1d      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ transformer_encoder[\u001b[38;5;34m0\u001b[0m… │\n","│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)      │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ global_max_pooling1d[\u001b[38;5;34m…\u001b[0m │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ dense_2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │          \u001b[38;5;34m2,570\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n","└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ positional_embedding_1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,273,600</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbedding</span>)     │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ transformer_encoder       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">543,776</span> │ positional_embedding_… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)      │                        │                │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ global_max_pooling1d      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ transformer_encoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)      │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_max_pooling1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n","└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,819,946\u001b[0m (22.20 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,819,946</span> (22.20 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,819,946\u001b[0m (22.20 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,819,946</span> (22.20 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"markdown","source":["# Entrenamiento"],"metadata":{"id":"hvu5Ng2YmUB1"}},{"cell_type":"code","source":["\"\"\"\n","callbacks = [\n","    keras.callbacks.ModelCheckpoint(\"transformer_encoder.h5\",\n","                                    save_best_only=True)\n","]\n","\"\"\"\n","\n","model.fit(int_train_ds,\n","          validation_data=int_val_ds,\n","          epochs=20,\n","          #callbacks=callbacks\n","          )\n","\n","\"\"\"\n","model = keras.models.load_model(\n","    \"transformer_encoder.h5\",\n","    custom_objects={\"TransformerEncoder\": TransformerEncoder}\n","    )\n","\n","#print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")\n","\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":871},"id":"5mdjBSy3OZ42","executionInfo":{"status":"ok","timestamp":1731425101510,"user_tz":300,"elapsed":64577,"user":{"displayName":"Diego Renza Torres","userId":"02863859277986193516"}},"outputId":"756e6774-a64c-4b65-b4a3-09a512e7d587"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 223ms/step - accuracy: 0.1135 - loss: 5.2722 - val_accuracy: 0.1550 - val_loss: 2.2174\n","Epoch 2/20\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 87ms/step - accuracy: 0.1602 - loss: 2.7760 - val_accuracy: 0.4800 - val_loss: 1.4796\n","Epoch 3/20\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.3671 - loss: 1.9746 - val_accuracy: 0.6800 - val_loss: 0.8790\n","Epoch 4/20\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.6802 - loss: 0.9185 - val_accuracy: 0.7900 - val_loss: 0.6186\n","Epoch 5/20\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.8344 - loss: 0.4789 - val_accuracy: 0.5900 - val_loss: 1.3309\n","Epoch 6/20\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.8892 - loss: 0.3203 - val_accuracy: 0.8500 - val_loss: 0.4216\n","Epoch 7/20\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.9283 - loss: 0.2082 - val_accuracy: 0.9000 - val_loss: 0.3286\n","Epoch 8/20\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.9611 - loss: 0.1251 - val_accuracy: 0.7900 - val_loss: 0.7132\n","Epoch 9/20\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.9446 - loss: 0.1378 - val_accuracy: 0.8650 - val_loss: 0.4454\n","Epoch 10/20\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.9834 - loss: 0.0373 - val_accuracy: 0.8500 - val_loss: 0.5737\n","Epoch 11/20\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.9733 - loss: 0.0999 - val_accuracy: 0.9300 - val_loss: 0.2370\n","Epoch 12/20\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.9902 - loss: 0.0447 - val_accuracy: 0.7950 - val_loss: 0.6828\n","Epoch 13/20\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.9939 - loss: 0.0371 - val_accuracy: 0.9450 - val_loss: 0.1671\n","Epoch 14/20\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - accuracy: 0.9970 - loss: 0.0144 - val_accuracy: 0.9500 - val_loss: 0.1842\n","Epoch 15/20\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.9936 - loss: 0.0315 - val_accuracy: 0.9150 - val_loss: 0.2113\n","Epoch 16/20\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.9965 - loss: 0.0136 - val_accuracy: 0.9350 - val_loss: 0.2432\n","Epoch 17/20\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.9958 - loss: 0.0147 - val_accuracy: 0.9250 - val_loss: 0.2307\n","Epoch 18/20\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9500 - val_loss: 0.1838\n","Epoch 19/20\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9400 - val_loss: 0.2279\n","Epoch 20/20\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.7000 - val_loss: 1.5522\n"]},{"output_type":"execute_result","data":{"text/plain":["'\\nmodel = keras.models.load_model(\\n    \"transformer_encoder.h5\",\\n    custom_objects={\"TransformerEncoder\": TransformerEncoder}\\n    )\\n\\n#print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}]}]}